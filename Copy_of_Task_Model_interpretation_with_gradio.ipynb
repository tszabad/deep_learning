{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Task_Model_interpretation_with_gradio.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tszabad/deep_learning/blob/main/Copy_of_Task_Model_interpretation_with_gradio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhgI9Bp10UBK"
      },
      "source": [
        "!pip install gradio > /dev/null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGJ8yxnL0UBO",
        "outputId": "5430547e-3d1f-4c7b-bd10-eed7824a2084"
      },
      "source": [
        "! python -m spacy download en \n",
        "! pip install wordcloud > /dev/null\n",
        "! wget https://gitlab.com/andras.simonyi/10_days_AI_training_data/raw/master/sentiment.tsv?inline=false -O sentiment.tsv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting en_core_web_sm==2.2.5\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz (12.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.0 MB 14.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (57.2.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (4.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n",
            "--2021-08-12 16:44:15--  https://gitlab.com/andras.simonyi/10_days_AI_training_data/raw/master/sentiment.tsv?inline=false\n",
            "Resolving gitlab.com (gitlab.com)... 172.65.251.78, 2606:4700:90:0:f22e:fbec:5bed:a9b9\n",
            "Connecting to gitlab.com (gitlab.com)|172.65.251.78|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/plain]\n",
            "Saving to: ‘sentiment.tsv’\n",
            "\n",
            "sentiment.tsv           [ <=>                ] 437.05K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2021-08-12 16:44:16 (23.2 MB/s) - ‘sentiment.tsv’ saved [447540]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKBKKRmr0UBR"
      },
      "source": [
        "# Sentiment classification\n",
        "\n",
        "The task is to classify one-sentence long movie reviews/opinions according to the sentiment they express. There are only two categories: positive and negative sentiment.\n",
        "\n",
        "\n",
        "> \"Data source: [UMICH SI650 - Sentiment Classification](https://www.kaggle.com/c/si650winter11/data)\n",
        "\n",
        "> Training data: 7086 lines. \n",
        "  \n",
        "> Format: 1|0 (tab) sentence\n",
        "\n",
        "> Test data: 33052 lines, each contains one sentence. \n",
        "\n",
        "> The data was originally collected from opinmind.com (which is no longer active).\"\n",
        "\n",
        "The data is in the file \"sentiment.tsv\".\n",
        "\n",
        "# Loading the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "ldiemPp60UBT",
        "outputId": "45f34f84-99eb-4b8f-de57-d019741a0344"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('sentiment.tsv', sep='\\t', \n",
        "                 quoting=3, # Quotes are _never_ field separators\n",
        "                 header=None)\n",
        "\n",
        "df.head()\n",
        "\n",
        "df = df[[1,0]] # reorder columns\n",
        "\n",
        "df.rename(columns={1:\"text\", 0:\"sentiment\"}, inplace=True) # rename columns\n",
        "\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The Da Vinci Code book is just awesome.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>this was the first clive cussler i've ever rea...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>i liked the Da Vinci Code a lot.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>i liked the Da Vinci Code a lot.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I liked the Da Vinci Code but it ultimatly did...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  sentiment\n",
              "0            The Da Vinci Code book is just awesome.          1\n",
              "1  this was the first clive cussler i've ever rea...          1\n",
              "2                   i liked the Da Vinci Code a lot.          1\n",
              "3                   i liked the Da Vinci Code a lot.          1\n",
              "4  I liked the Da Vinci Code but it ultimatly did...          1"
            ]
          },
          "execution_count": 3,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6M-6ekl20UBV"
      },
      "source": [
        "# Splitting into train, validation and test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UAGsAKMq0UBW"
      },
      "source": [
        "Before doing anything else (!) we divide our data into train, validation and test parts,"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bM7Q-Y80UBX",
        "outputId": "532551c3-e150-467e-d072-37f85189fb30"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df_train, df_test_valid = train_test_split(df, test_size = 0.2, shuffle=True, \n",
        "                                           random_state=13) # fix the seed\n",
        "\n",
        "df_test, df_valid = train_test_split(df_test_valid, test_size = 0.5)\n",
        "\n",
        "print(len(df_train), len(df_valid), len(df_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5668 709 709\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6hEoSSX0UBY"
      },
      "source": [
        "# Inspecting the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "LkvBSiN70UBZ",
        "outputId": "a5d21ce1-8c13-43e8-87e0-9056add3ae0c"
      },
      "source": [
        "df_train.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>5668.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.559104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.496538</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         sentiment\n",
              "count  5668.000000\n",
              "mean      0.559104\n",
              "std       0.496538\n",
              "min       0.000000\n",
              "25%       0.000000\n",
              "50%       1.000000\n",
              "75%       1.000000\n",
              "max       1.000000"
            ]
          },
          "execution_count": 5,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQJso_eX0UBa"
      },
      "source": [
        "We can examine the lengths of sentences as well."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-qHiwJ30UBb",
        "outputId": "2af87a56-1652-44d0-9c43-8f9cbfd59936"
      },
      "source": [
        "n_chars = df_train.text.apply(lambda x: len(x))\n",
        "\n",
        "n_chars.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "count    5668.000000\n",
              "mean       60.100565\n",
              "std        37.931478\n",
              "min        18.000000\n",
              "25%        32.000000\n",
              "50%        48.000000\n",
              "75%        77.000000\n",
              "max       203.000000\n",
              "Name: text, dtype: float64"
            ]
          },
          "execution_count": 6,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NL4MkuRW0UBc"
      },
      "source": [
        "The first sentence with the maximal length:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "Emk3Zqtt0UBc",
        "outputId": "27edd8c9-3d0c-4118-e3fd-187cbae5f282"
      },
      "source": [
        "long_sentence = df_train.loc[n_chars.idxmax(), \"text\"]\n",
        "long_sentence"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'A mother in Georgia wants her local school board to take Harry Potter out of the schools and libraries because, in her opinion, reading Harry Potter leads to witchcraft, which according to her is evil...'"
            ]
          },
          "execution_count": 7,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-P7kgAV0UBd"
      },
      "source": [
        "# Bag of words (BoW) representation of the texts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SquqqlL0UBd"
      },
      "source": [
        "We will represent each text as a (sparse) vector of lemma (word root) counts for frequent lemmas in the training data. \n",
        "\n",
        "For tokenization and lemmatization we use [spaCy](https://spacy.io/), an open source Python NLP library, which can produce a list of unique lemma ids from the text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUyK3mo00UBe"
      },
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en\", disable=[\"parser\", \"ner\"]) # We need only the tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-vZs9mV0UBe"
      },
      "source": [
        "spaCy can produce spaCy Doc objects from texts that contain their linguistic analysis, among others lemmas and their unique spaCy string ids."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7IFEJXb0UBf",
        "outputId": "b0362bf9-0d25-4bb2-c0c2-06791b68d72b"
      },
      "source": [
        "doc = nlp(long_sentence)\n",
        "type(doc)\n",
        "\n",
        "print([token.lemma_ for token in doc ]) # Lemmas\n",
        "\n",
        "print([token.lemma for token in doc]) # Corresponding unique ids"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['a', 'mother', 'in', 'Georgia', 'want', '-PRON-', 'local', 'school', 'board', 'to', 'take', 'Harry', 'Potter', 'out', 'of', 'the', 'school', 'and', 'library', 'because', ',', 'in', '-PRON-', 'opinion', ',', 'read', 'Harry', 'Potter', 'lead', 'to', 'witchcraft', ',', 'which', 'accord', 'to', '-PRON-', 'be', 'evil', '...']\n",
            "[11901859001352538922, 7963322251145911254, 3002984154512732771, 309210702643012516, 7597692042947428029, 561228191312463089, 16319852998319793599, 13293160603192985325, 14899812206273857344, 3791531372978436496, 6789454535283781228, 5164779919001708464, 2416965663249996073, 1696981056005371314, 886050111519832510, 7425985699627899538, 13293160603192985325, 2283656566040971221, 1785747669126016609, 16950148841647037698, 2593208677638477497, 3002984154512732771, 561228191312463089, 14536103007527724270, 2593208677638477497, 11792590063656742891, 5164779919001708464, 2416965663249996073, 82546335403996757, 3791531372978436496, 17905374590688478165, 2593208677638477497, 7063653163634019529, 701735504652304602, 3791531372978436496, 561228191312463089, 10382539506755952630, 15036397985088571056, 10875615029400813363]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6c84E6cJ0UBf"
      },
      "source": [
        "Now we have to convert these lists into BoW vectors. We could \"roll our own\", but, fortunately, scikit-learn has a feature extractor doing exactly that, the [CountVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer) so, for the sake of simplicity, we will use that along with spaCy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMCuQbt90UBg",
        "outputId": "7cadbb6c-c887-4bef-9743-0391a9f02dd3"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "cv = CountVectorizer(analyzer=lambda s: [token.lemma for token in nlp(s)], # use spaCy for analysis\n",
        "                     min_df= 0.001) # Ignore lemmas with lower document frequency\n",
        "cv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "CountVectorizer(analyzer=<function <lambda> at 0x7f173da70950>, binary=False,\n",
              "                decode_error='strict', dtype=<class 'numpy.int64'>,\n",
              "                encoding='utf-8', input='content', lowercase=True, max_df=1.0,\n",
              "                max_features=None, min_df=0.001, ngram_range=(1, 1),\n",
              "                preprocessor=None, stop_words=None, strip_accents=None,\n",
              "                token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None,\n",
              "                vocabulary=None)"
            ]
          },
          "execution_count": 10,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8eeocb-B0UBh",
        "outputId": "27b4fd4a-7254-4115-9ddd-c6f3d3719b89"
      },
      "source": [
        "sents = [\"I hate this movie.\", \"The movie is the worst I've seen.\"]\n",
        "bows = cv.fit_transform(sents).toarray() # CountVectorizer produces a sparse matrix so we convert to ndarray\n",
        "bows"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1, 1, 0, 1, 0, 0, 0, 1, 0, 1],\n",
              "       [1, 0, 2, 0, 1, 1, 1, 1, 1, 1]])"
            ]
          },
          "execution_count": 11,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNMk9BEO0UBh"
      },
      "source": [
        "Using the CountVectorizer we convert the text columns of our train, validation and  test data into three sparse matrices."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJhm7tXw0UBh",
        "outputId": "2f74368e-91b7-42ea-f3ac-c1ccf65c6744"
      },
      "source": [
        "bows_train = cv.fit_transform(df_train.text)\n",
        "bows_train.sort_indices() # comes from TF2.0 sparse implementation, obscure requirement\n",
        "bow_length = bows_train.shape[1]\n",
        "print(\"BoW length:\", bow_length)\n",
        "bows_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BoW length: 374\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<5668x374 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 63241 stored elements in Compressed Sparse Row format>"
            ]
          },
          "execution_count": 12,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IrxCc7FR0UBh",
        "outputId": "f7ef4a75-b730-4def-c0fa-92daf5589134"
      },
      "source": [
        "print(bows_train[0,:])\n",
        "\n",
        "bows_valid = cv.transform(df_valid.text)\n",
        "bows_valid.sort_indices() # comes from TF2.0 sparse implementation, obscure requirement\n",
        "bows_test = cv.transform(df_test.text)\n",
        "bows_test.sort_indices() # comes from TF2.0 sparse implementation, obscure requirement"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  (0, 14)\t1\n",
            "  (0, 49)\t1\n",
            "  (0, 54)\t2\n",
            "  (0, 100)\t1\n",
            "  (0, 186)\t1\n",
            "  (0, 257)\t1\n",
            "  (0, 365)\t1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9WJ15-p0UBi"
      },
      "source": [
        "# The model\n",
        "\n",
        "We build a feed-forward neural network for our binary classification task, which will be trained with cross-entropy loss and minibatch SGD."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XnG1CA5G0UBj",
        "outputId": "a1fdc409-c987-4b8c-88e9-2e2a874a4be6"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "# Parameters\n",
        "############\n",
        "\n",
        "hidden_size = 100\n",
        "\n",
        "# Model\n",
        "#######\n",
        "\n",
        "inputs = Input(shape=(bow_length,))\n",
        "\n",
        "# Hidden layer\n",
        "\n",
        "hidden_output = Dense(hidden_size, activation='relu')(inputs)\n",
        "\n",
        "# Softmax \n",
        "\n",
        "predictions = Dense(2, activation='softmax')(hidden_output)\n",
        "\n",
        "\n",
        "# Full model\n",
        "\n",
        "model = Model(inputs=inputs, outputs=predictions)\n",
        "\n",
        "# Optimizer\n",
        "####################\n",
        "\n",
        "optimizer = SGD(lr=0.1)\n",
        " \n",
        "\n",
        "# Compilation and fitting \n",
        "#########################\n",
        "\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss='sparse_categorical_crossentropy', # we use this cross entropy variant as the input is not \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Training\n",
        "\n",
        "model.fit(x=bows_train, \n",
        "          y=df_train.sentiment.values,\n",
        "          validation_data=(bows_valid, df_valid.sentiment.values),\n",
        "          epochs=10,\n",
        "          batch_size=200)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model/dense/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model/dense/embedding_lookup_sparse/Reshape:0\", shape=(None, 100), dtype=float32), dense_shape=Tensor(\"gradient_tape/model/dense/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "29/29 [==============================] - 1s 8ms/step - loss: 0.5254 - accuracy: 0.8373 - val_loss: 0.3846 - val_accuracy: 0.9422\n",
            "Epoch 2/10\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.3093 - accuracy: 0.9564 - val_loss: 0.2387 - val_accuracy: 0.9690\n",
            "Epoch 3/10\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.1961 - accuracy: 0.9697 - val_loss: 0.1579 - val_accuracy: 0.9774\n",
            "Epoch 4/10\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.1389 - accuracy: 0.9739 - val_loss: 0.1174 - val_accuracy: 0.9831\n",
            "Epoch 5/10\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.1071 - accuracy: 0.9751 - val_loss: 0.0940 - val_accuracy: 0.9774\n",
            "Epoch 6/10\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0879 - accuracy: 0.9776 - val_loss: 0.0793 - val_accuracy: 0.9746\n",
            "Epoch 7/10\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0752 - accuracy: 0.9799 - val_loss: 0.0691 - val_accuracy: 0.9746\n",
            "Epoch 8/10\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.0659 - accuracy: 0.9804 - val_loss: 0.0608 - val_accuracy: 0.9859\n",
            "Epoch 9/10\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.0591 - accuracy: 0.9827 - val_loss: 0.0558 - val_accuracy: 0.9831\n",
            "Epoch 10/10\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.0536 - accuracy: 0.9838 - val_loss: 0.0514 - val_accuracy: 0.9831\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f16fa67af50>"
            ]
          },
          "execution_count": 14,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2z1zrXGW0UBk"
      },
      "source": [
        "# Implement a function, that \n",
        "# assumes model and CountVectorizer to be available in the global namespace\n",
        "# receives a string input\n",
        "# processes it with CountVectorizer\n",
        "# takes the processed BOW representation\n",
        "# feeds it to the model for prediction\n",
        "# formats the prediction as a dict with the keys \"Negative\" and \"Positive\"\n",
        "# 0th prediction corresponds to Negative probability, 1st to Positive\n",
        "# cast the probabilities to simple Python floats, Numpy floats do NOT work.\n",
        "# return this dict\n",
        "def predict_sentiment(input_string):\n",
        "    global model\n",
        "    global cv\n",
        "    goodbad = [\"Negative\",\"Positive\"]\n",
        "    bow = cv.transform([input_string])\n",
        "    prob_pred = model.predict(bow[0])\n",
        "    return {\"Negative\":float(prob_pred[0,0]),\"Positive\":float(prob_pred[0,1])}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_L734w7w0UBk",
        "outputId": "695124c2-3b03-4637-b3ed-55a90913ceea"
      },
      "source": [
        "# Test the function!\n",
        "predict_sentiment(\"This film was pretty amazing.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'Negative': 0.41229361295700073, 'Positive': 0.5877063870429993}"
            ]
          },
          "execution_count": 16,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEF8tkKIj05_"
      },
      "source": [
        "#Task1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 963
        },
        "id": "nugaDH0w0UBl",
        "outputId": "c6492e8d-e029-46c7-af92-ce5cce7c2a59"
      },
      "source": [
        "# Import Gradio, and build an interface\n",
        "# Input is a textbox, outputs are \"label\"-s, and interpretation is set to default.\n",
        "\n",
        "import gradio as gr\n",
        "iface = gr.Interface(\n",
        "  fn=predict_sentiment, \n",
        "  inputs=gr.inputs.Textbox(lines=2, placeholder=\"Enter sentiment here...\"), \n",
        "  outputs=\"label\", interpretation=\"default\", allow_flagging=True, flagging_dir = \"flagged/\")\n",
        "# Launch the interface, possibly use debug=True to make your life easier!\n",
        "iface.launch(debug=True) #try to launch it"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "This share link will expire in 24 hours. If you need a permanent link, visit: https://gradio.app/introducing-hosted (NEW!)\n",
            "Running on External URL: https://18271.gradio.app\n",
            "Interface loading below...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"900\"\n",
              "            height=\"500\"\n",
              "            src=\"https://18271.gradio.app\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7f16f3ad1b10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 default\n",
            "0 default\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-26d77c1983da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m   outputs=\"label\", interpretation=\"default\", allow_flagging=True, flagging_dir = \"flagged/\")\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Launch the interface, possibly use debug=True to make your life easier!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0miface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#try to launch it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gradio/interface.py\u001b[0m in \u001b[0;36mlaunch\u001b[0;34m(self, inline, inbrowser, share, debug, auth, auth_message, private_endpoint, prevent_thread_lock)\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m                 \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 587\u001b[0;31m                 \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    588\u001b[0m         \u001b[0mis_in_interactive_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ps1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteractive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mprevent_thread_lock\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_in_interactive_mode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZWny9_N0UBl"
      },
      "source": [
        "Additional tasks: \n",
        "\n",
        "- Use the model interpretation tool of Gradio to observe some counterexamples, that do not work well!\n",
        "- Set the flagging folder and use the flagging capability of Gradio to collect 15 badly behaving examples in a CSV file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-cWRfrdw0RfI"
      },
      "source": [
        "#Task2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNL_R-Of0THb"
      },
      "source": [
        "from urllib.request import urlretrieve\n",
        "urlretrieve(\"https://gr-models.s3-us-west-2.amazonaws.com/mnist-model.h5\", \"mnist-model.h5\")\n",
        "model1 = tf.keras.models.load_model(\"mnist-model.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8vSZMGqLC6Q"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3_WtXpp0WRJ"
      },
      "source": [
        "def recognize_digit(image):\n",
        "    print(image.shape)\n",
        "    image = image.reshape(1,784)\n",
        "    print(image.shape)\n",
        "    prediction = model1.predict(image).tolist()[0]\n",
        "    return {str(i): prediction[i] for i in range(10)}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wqJv2Bc0iUH"
      },
      "source": [
        "im = gr.inputs.Image(shape=(28,28), image_mode=\"L\", invert_colors=False, source=\"canvas\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9-22GFiw0r5y",
        "outputId": "801f4816-7de1-45e8-dd19-3c90745183e5"
      },
      "source": [
        "iface = gr.Interface(fn=recognize_digit, inputs=im, outputs=gr.outputs.Label(num_top_classes= 4), live = True)\n",
        "iface.launch(debug=True) #try to launch it"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "This share link will expire in 24 hours. If you need a permanent link, visit: https://gradio.app/introducing-hosted (NEW!)\n",
            "Running on External URL: https://44881.gradio.app\n",
            "Interface loading below...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"900\"\n",
              "            height=\"500\"\n",
              "            src=\"https://44881.gradio.app\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7f16ec86afd0>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(28, 28)\n",
            "(1, 784)\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 784) for input KerasTensor(type_spec=TensorSpec(shape=(None, 784), dtype=tf.float32, name='reshape_input'), name='reshape_input', description=\"created by layer 'reshape_input'\"), but it was called on an input with incompatible shape (None, 1).\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[2021-08-12 17:34:06,712] ERROR in app: Exception on /api/predict/ [POST]\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/flask/app.py\", line 2447, in wsgi_app\n",
            "    response = self.full_dispatch_request()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/flask/app.py\", line 1952, in full_dispatch_request\n",
            "    rv = self.handle_user_exception(e)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/flask_cors/extension.py\", line 165, in wrapped_function\n",
            "    return cors_after_request(app.make_response(f(*args, **kwargs)))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/flask/app.py\", line 1821, in handle_user_exception\n",
            "    reraise(exc_type, exc_value, tb)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/flask/_compat.py\", line 39, in reraise\n",
            "    raise value\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/flask/app.py\", line 1950, in full_dispatch_request\n",
            "    rv = self.dispatch_request()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/flask/app.py\", line 1936, in dispatch_request\n",
            "    return self.view_functions[rule.endpoint](**req.view_args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/gradio/networking.py\", line 91, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/gradio/networking.py\", line 179, in predict\n",
            "    prediction, durations = app.interface.process(raw_input)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/gradio/interface.py\", line 328, in process\n",
            "    predictions, durations = self.run_prediction(processed_input, return_duration=True)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/gradio/interface.py\", line 306, in run_prediction\n",
            "    raise exception\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/gradio/interface.py\", line 301, in run_prediction\n",
            "    prediction = predict_fn(*processed_input)\n",
            "  File \"<ipython-input-72-9ccd392ac098>\", line 5, in recognize_digit\n",
            "    prediction = model1.predict(image[0])#.tolist()[0]\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\", line 1727, in predict\n",
            "    tmp_batch_outputs = self.predict_function(iterator)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\", line 889, in __call__\n",
            "    result = self._call(*args, **kwds)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\", line 933, in _call\n",
            "    self._initialize(args, kwds, add_initializers_to=initializers)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\", line 764, in _initialize\n",
            "    *args, **kwds))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\", line 3050, in _get_concrete_function_internal_garbage_collected\n",
            "    graph_function, _ = self._maybe_define_function(args, kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\", line 3444, in _maybe_define_function\n",
            "    graph_function = self._create_graph_function(args, kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\", line 3289, in _create_graph_function\n",
            "    capture_by_value=self._capture_by_value),\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\", line 999, in func_graph_from_py_func\n",
            "    func_outputs = python_func(*func_args, **func_kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\", line 672, in wrapped_fn\n",
            "    out = weak_wrapped_fn().__wrapped__(*args, **kwds)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\", line 986, in wrapper\n",
            "    raise e.ag_error_metadata.to_exception(e)\n",
            "ValueError: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1569 predict_function  *\n",
            "        return step_function(self, iterator)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1559 step_function  **\n",
            "        outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:1285 run\n",
            "        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:2833 call_for_each_replica\n",
            "        return self._call_for_each_replica(fn, args, kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:3608 _call_for_each_replica\n",
            "        return fn(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1552 run_step  **\n",
            "        outputs = model.predict_step(data)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1525 predict_step\n",
            "        return self(x, training=False)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:1030 __call__\n",
            "        outputs = call_fn(inputs, *args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:380 call\n",
            "        return super(Sequential, self).call(inputs, training=training, mask=mask)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py:421 call\n",
            "        inputs, training=training, mask=mask)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py:556 _run_internal_graph\n",
            "        outputs = node.layer(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:1030 __call__\n",
            "        outputs = call_fn(inputs, *args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/core.py:557 call\n",
            "        result.set_shape(self.compute_output_shape(inputs.shape))\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/core.py:548 compute_output_shape\n",
            "        self.target_shape)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/core.py:536 _fix_unknown_dimension\n",
            "        raise ValueError(msg)\n",
            "\n",
            "    ValueError: total size of new array must be unchanged, input_shape = [1], output_shape = [28, 28, 1]\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(28, 28)\n",
            "(1, 784)\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 784) for input KerasTensor(type_spec=TensorSpec(shape=(None, 784), dtype=tf.float32, name='reshape_input'), name='reshape_input', description=\"created by layer 'reshape_input'\"), but it was called on an input with incompatible shape (None, 1).\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[2021-08-12 17:34:09,436] ERROR in app: Exception on /api/predict/ [POST]\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/flask/app.py\", line 2447, in wsgi_app\n",
            "    response = self.full_dispatch_request()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/flask/app.py\", line 1952, in full_dispatch_request\n",
            "    rv = self.handle_user_exception(e)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/flask_cors/extension.py\", line 165, in wrapped_function\n",
            "    return cors_after_request(app.make_response(f(*args, **kwargs)))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/flask/app.py\", line 1821, in handle_user_exception\n",
            "    reraise(exc_type, exc_value, tb)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/flask/_compat.py\", line 39, in reraise\n",
            "    raise value\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/flask/app.py\", line 1950, in full_dispatch_request\n",
            "    rv = self.dispatch_request()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/flask/app.py\", line 1936, in dispatch_request\n",
            "    return self.view_functions[rule.endpoint](**req.view_args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/gradio/networking.py\", line 91, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/gradio/networking.py\", line 179, in predict\n",
            "    prediction, durations = app.interface.process(raw_input)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/gradio/interface.py\", line 328, in process\n",
            "    predictions, durations = self.run_prediction(processed_input, return_duration=True)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/gradio/interface.py\", line 306, in run_prediction\n",
            "    raise exception\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/gradio/interface.py\", line 301, in run_prediction\n",
            "    prediction = predict_fn(*processed_input)\n",
            "  File \"<ipython-input-72-9ccd392ac098>\", line 5, in recognize_digit\n",
            "    prediction = model1.predict(image[0])#.tolist()[0]\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\", line 1727, in predict\n",
            "    tmp_batch_outputs = self.predict_function(iterator)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\", line 889, in __call__\n",
            "    result = self._call(*args, **kwds)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\", line 924, in _call\n",
            "    results = self._stateful_fn(*args, **kwds)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\", line 3022, in __call__\n",
            "    filtered_flat_args) = self._maybe_define_function(args, kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\", line 3441, in _maybe_define_function\n",
            "    args, kwargs, flat_args, filtered_flat_args, cache_key_context)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\", line 3363, in _define_function_with_shape_relaxation\n",
            "    args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\", line 3289, in _create_graph_function\n",
            "    capture_by_value=self._capture_by_value),\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\", line 999, in func_graph_from_py_func\n",
            "    func_outputs = python_func(*func_args, **func_kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\", line 672, in wrapped_fn\n",
            "    out = weak_wrapped_fn().__wrapped__(*args, **kwds)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\", line 986, in wrapper\n",
            "    raise e.ag_error_metadata.to_exception(e)\n",
            "ValueError: in user code:\n",
            "\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1569 predict_function  *\n",
            "        return step_function(self, iterator)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1559 step_function  **\n",
            "        outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:1285 run\n",
            "        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:2833 call_for_each_replica\n",
            "        return self._call_for_each_replica(fn, args, kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:3608 _call_for_each_replica\n",
            "        return fn(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1552 run_step  **\n",
            "        outputs = model.predict_step(data)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1525 predict_step\n",
            "        return self(x, training=False)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:1030 __call__\n",
            "        outputs = call_fn(inputs, *args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:380 call\n",
            "        return super(Sequential, self).call(inputs, training=training, mask=mask)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py:421 call\n",
            "        inputs, training=training, mask=mask)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py:556 _run_internal_graph\n",
            "        outputs = node.layer(*args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:1030 __call__\n",
            "        outputs = call_fn(inputs, *args, **kwargs)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/core.py:557 call\n",
            "        result.set_shape(self.compute_output_shape(inputs.shape))\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/core.py:548 compute_output_shape\n",
            "        self.target_shape)\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/core.py:536 _fix_unknown_dimension\n",
            "        raise ValueError(msg)\n",
            "\n",
            "    ValueError: total size of new array must be unchanged, input_shape = [1], output_shape = [28, 28, 1]\n",
            "\n"
          ]
        }
      ]
    }
  ]
}