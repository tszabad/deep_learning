{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copy of Day06-Task_Convolutional_Networks_on_CIFAR10_handout.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tszabad/deep_learning/blob/main/Copy_of_Day06_Task_Convolutional_Networks_on_CIFAR10_handout.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSHhdguTHm0N"
      },
      "source": [
        "# Task: CIFAR-10 classification\n",
        "\n",
        "The [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html)\n",
        "\n",
        "> \"consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.\n",
        "\n",
        ">The dataset is divided into five training batches and one test batch, each with 10000 images. The test batch contains exactly 1000 randomly-selected images from each class. The training batches contain the remaining images in random order, but some training batches may contain more images from one class than another. Between them, the training batches contain exactly 5000 images from each class.\"\n",
        "\n",
        "<img src=\"http://drive.google.com/uc?export=view&id=1wlfkvZgS0oBDwxKicWmYgtsJmP3IcMdj\">\n",
        "\n",
        "### Categories:\n",
        "\n",
        "- airplane \t\t\t\t\t\t\t\t\t\t\n",
        "- automobile \t\t\t\t\t\t\t\t\t\t\n",
        "- bird \t\t\t\t\t\t\t\t\t\t\n",
        "- cat \t\t\t\t\t\t\t\t\t\t\n",
        "- deer \t\t\t\t\t\t\t\t\t\t\n",
        "- dog \t\t\t\t\t\t\t\t\t\t\n",
        "- frog \t\t\t\t\t\t\t\t\t\t\n",
        "- horse \t\t\t\t\t\t\t\t\t\t\n",
        "- ship \t\t\t\t\t\t\t\t\t\t\n",
        "- truck"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIX2ehpiHm0S"
      },
      "source": [
        "# Preliminaries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-05-01T08:39:01.205778Z",
          "start_time": "2019-05-01T08:39:00.058811Z"
        },
        "collapsed": true,
        "id": "sTT_MyHltNm4"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout, Conv2D, MaxPool2D, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adadelta, Adam, SGD\n",
        "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
        "from tensorflow.keras.regularizers import l1\n",
        "from tensorflow.keras.backend import clear_session\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "from tensorflow.keras.initializers import glorot_normal\n",
        "# from tensorboardcolab import TensorBoardColab \n",
        "\n",
        "# Fix seeds for (hopefully) reproducible results\n",
        "from numpy.random import seed\n",
        "seed(14)\n",
        "tf.random.set_seed(19)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7d9_yHMEtNnG"
      },
      "source": [
        "Download the data if necessary and load it:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-05-01T08:39:36.264800Z",
          "start_time": "2019-05-01T08:39:01.207234Z"
        },
        "collapsed": true,
        "id": "jFmPQL0xM_4p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e3b435b-e4b4-48df-dd41-f2dad589b358"
      },
      "source": [
        "train, test = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "train_images, train_labels = train\n",
        "\n",
        "valid_test_images, valid_test_labels = test\n",
        "print(train_images[0])\n",
        "\n",
        "train_images = train_images / 255.\n",
        "print(train_images[0])\n",
        "print(train_images[0].shape)\n",
        "\n",
        "valid_test_images = valid_test_images / 255.\n",
        "\n",
        "valid_images = valid_test_images[:5000]\n",
        "valid_labels = valid_test_labels[:5000]\n",
        "test_images = valid_test_images[5000:]\n",
        "test_labels = valid_test_labels[5000:]\n",
        "\n",
        "print(train_images.shape, valid_images.shape, test_images.shape)\n",
        "print(train_labels.shape, valid_labels.shape, test_labels.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[ 59  62  63]\n",
            "  [ 43  46  45]\n",
            "  [ 50  48  43]\n",
            "  ...\n",
            "  [158 132 108]\n",
            "  [152 125 102]\n",
            "  [148 124 103]]\n",
            "\n",
            " [[ 16  20  20]\n",
            "  [  0   0   0]\n",
            "  [ 18   8   0]\n",
            "  ...\n",
            "  [123  88  55]\n",
            "  [119  83  50]\n",
            "  [122  87  57]]\n",
            "\n",
            " [[ 25  24  21]\n",
            "  [ 16   7   0]\n",
            "  [ 49  27   8]\n",
            "  ...\n",
            "  [118  84  50]\n",
            "  [120  84  50]\n",
            "  [109  73  42]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[208 170  96]\n",
            "  [201 153  34]\n",
            "  [198 161  26]\n",
            "  ...\n",
            "  [160 133  70]\n",
            "  [ 56  31   7]\n",
            "  [ 53  34  20]]\n",
            "\n",
            " [[180 139  96]\n",
            "  [173 123  42]\n",
            "  [186 144  30]\n",
            "  ...\n",
            "  [184 148  94]\n",
            "  [ 97  62  34]\n",
            "  [ 83  53  34]]\n",
            "\n",
            " [[177 144 116]\n",
            "  [168 129  94]\n",
            "  [179 142  87]\n",
            "  ...\n",
            "  [216 184 140]\n",
            "  [151 118  84]\n",
            "  [123  92  72]]]\n",
            "[[[0.23137255 0.24313725 0.24705882]\n",
            "  [0.16862745 0.18039216 0.17647059]\n",
            "  [0.19607843 0.18823529 0.16862745]\n",
            "  ...\n",
            "  [0.61960784 0.51764706 0.42352941]\n",
            "  [0.59607843 0.49019608 0.4       ]\n",
            "  [0.58039216 0.48627451 0.40392157]]\n",
            "\n",
            " [[0.0627451  0.07843137 0.07843137]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.07058824 0.03137255 0.        ]\n",
            "  ...\n",
            "  [0.48235294 0.34509804 0.21568627]\n",
            "  [0.46666667 0.3254902  0.19607843]\n",
            "  [0.47843137 0.34117647 0.22352941]]\n",
            "\n",
            " [[0.09803922 0.09411765 0.08235294]\n",
            "  [0.0627451  0.02745098 0.        ]\n",
            "  [0.19215686 0.10588235 0.03137255]\n",
            "  ...\n",
            "  [0.4627451  0.32941176 0.19607843]\n",
            "  [0.47058824 0.32941176 0.19607843]\n",
            "  [0.42745098 0.28627451 0.16470588]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0.81568627 0.66666667 0.37647059]\n",
            "  [0.78823529 0.6        0.13333333]\n",
            "  [0.77647059 0.63137255 0.10196078]\n",
            "  ...\n",
            "  [0.62745098 0.52156863 0.2745098 ]\n",
            "  [0.21960784 0.12156863 0.02745098]\n",
            "  [0.20784314 0.13333333 0.07843137]]\n",
            "\n",
            " [[0.70588235 0.54509804 0.37647059]\n",
            "  [0.67843137 0.48235294 0.16470588]\n",
            "  [0.72941176 0.56470588 0.11764706]\n",
            "  ...\n",
            "  [0.72156863 0.58039216 0.36862745]\n",
            "  [0.38039216 0.24313725 0.13333333]\n",
            "  [0.3254902  0.20784314 0.13333333]]\n",
            "\n",
            " [[0.69411765 0.56470588 0.45490196]\n",
            "  [0.65882353 0.50588235 0.36862745]\n",
            "  [0.70196078 0.55686275 0.34117647]\n",
            "  ...\n",
            "  [0.84705882 0.72156863 0.54901961]\n",
            "  [0.59215686 0.4627451  0.32941176]\n",
            "  [0.48235294 0.36078431 0.28235294]]]\n",
            "(32, 32, 3)\n",
            "(50000, 32, 32, 3) (5000, 32, 32, 3) (5000, 32, 32, 3)\n",
            "(50000, 1) (5000, 1) (5000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxyeFqibHm05"
      },
      "source": [
        "# Model\n",
        "\n",
        "## Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-05-01T08:39:36.268218Z",
          "start_time": "2019-05-01T08:39:36.266265Z"
        },
        "collapsed": true,
        "id": "S075_4a6tNna"
      },
      "source": [
        "n_classes = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-05-01T08:39:36.277888Z",
          "start_time": "2019-05-01T08:39:36.269933Z"
        },
        "collapsed": true,
        "id": "2w8ozIvExC_g"
      },
      "source": [
        "# TASK - Hyperparameters\n",
        "# Fill in the initial values!\n",
        "# Later, experiment!\n",
        "#############################\n",
        "\n",
        "\n",
        "# dropout - Something between 0.0 < dropout_rate < 1.0, think in \"tens of percentages\" as default\n",
        "# dropout rate for conv layers\n",
        "dropout_rate_1 = 0.3\n",
        "# dropout rate for fully connected layers\n",
        "dropout_rate_2 = 0.4\n",
        "\n",
        "# Choose an appropriate batch size for the training!\n",
        "batch_size = 192\n",
        "\n",
        "# Choose an appropriate number of epochs\n",
        "epoch_count = 30\n",
        "\n",
        "# These are the default parameters, you can experiment with learning rates, schedules, ..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACdo3SEitNnl"
      },
      "source": [
        "## Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-05-01T08:39:36.404889Z",
          "start_time": "2019-05-01T08:39:36.282271Z"
        },
        "collapsed": true,
        "id": "o8OgyCFaHm1H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b55ca355-d6b5-49ba-a137-706602142555"
      },
      "source": [
        "# adapted from https://github.com/jtopor/CUNY-MSDA-661/blob/master/CIFAR-CNN/TF-Layers-CIFAR-GITHUB-v3.py\n",
        "\n",
        "\n",
        "tf.compat.v1.reset_default_graph() # It's good practice to clean and reset everything\n",
        "clear_session()          # even using Keras\n",
        "\n",
        "\n",
        "# WE USE FUNCTIONAL API!\n",
        "# (Could be different, but not now...)\n",
        "\n",
        "\n",
        "\n",
        "# Model\n",
        "#######\n",
        "\n",
        "# Define the input!\n",
        "# Remember, we have pictures with 32x32 pixels and 3 color channels\n",
        "# Disregard batch size, Keras will do that for us.\n",
        "x = Input(shape=(32, 32, 3))\n",
        "# Convolutional Layer #1: (batch_size, 32, 32, 3) -> (batch_size, 32, 32, 64)\n",
        "# Define a \"normal\" convolutional layer for images (not a single sequence, so ?D)\n",
        "# There should be 64 convolutional units\n",
        "# The kernel should be 5 in width and heigth\n",
        "# There should be padding so that the input and output dimensions would be equivalent\n",
        "# The non-linearity should be ReLU\n",
        "conv1 = Conv2D(64, activation='relu', kernel_size = (4,4), padding=\"valid\" )(x)\n",
        " \n",
        "# Pooling Layer #1: (batch_size, 32, 32, 64) -> (batch_size, 16, 16, 64)\n",
        "# Define a maximum based pooling layer with appropriate dimensions\n",
        "# The pooling size should be 2,2 and stride 2\n",
        "pool1 = MaxPool2D(pool_size=(2, 2), strides=2)(conv1)\n",
        "\n",
        "# Define a dropout layer with using the first dropout rate parameter\n",
        "dropout1 = Dropout(dropout_rate_1)(pool1)\n",
        "\n",
        "# Convolutional Layer #2: (batch_size, 16, 16, 64) -> (batch_size, 16, 16, 64)\n",
        "# Repeat the prior conv layer\n",
        "# Watch for the right input\n",
        "conv2 = Conv2D(64, activation='relu', kernel_size = (4,4), padding=\"valid\" )(dropout1)\n",
        "  \n",
        "# Pooling Layer #2: (batch_size, 16, 16, 64) -> (batch_size, 8, 8, 64)\n",
        "# Repeat the prior pooling layer\n",
        "# Watch for the right input\n",
        "pool2 = MaxPool2D(pool_size=(2, 2), strides=2)(conv2)\n",
        "\n",
        "# Define a dropout layer with using the FIRST dropout rate parameter\n",
        "dropout2 = Dropout(dropout_rate_2)(pool2)\n",
        "\n",
        "# Convert tensors into vectors: (batch_size, 8, 8, 64) -> (batch_size, 4096)\n",
        "# Use a single KERAS function, NO numpy or reshape magic!\n",
        "# Hint: the result is not 2D but \"flat\"\n",
        "pool2_flat = Flatten()(dropout2)\n",
        "\n",
        "# Fully connected Layer #1: (batch_size, 4096)-> (batch_size, 512)\n",
        "# Define a fully connected layer with 512 nodes and ReLU\n",
        "dense1 = Dense(512, activation=\"relu\")(pool2_flat)\n",
        "\n",
        "# Define a dropout layer with using the SECOND dropout rate parameter\n",
        "dropout3 = Dropout(dropout_rate_2)(dense1)\n",
        "\n",
        "# Dense Layer #1: (batch_size, 512)-> (batch_size, 256)\n",
        "# Define a fully connected layer with 256 nodes and ReLU\n",
        "dense2 = Dense(256, activation=\"relu\")(dropout3)\n",
        "\n",
        "# Define a dropout layer with using the SECOND dropout rate parameter\n",
        "dropout4 = Dropout(dropout_rate_2)(dense2)\n",
        "\n",
        "# Logits layer: (batch_size, 256) -> (batch_size, 10)\n",
        "# Define a fully connected layer with ??? nodes\n",
        "# Think about it, what shape should the output be?\n",
        "# What activation?\n",
        "# Think about it: we are in a classification problem!\n",
        "predictions = Dense(10, activation = \"Softmax\")(dropout4)\n",
        "\n",
        "# Full model\n",
        "# Instantiate (initialize) the model with inputs and outputs\n",
        "\n",
        "model = Model(inputs=x, outputs=predictions, name=\"CIFAR_10\")\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"CIFAR_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 29, 29, 64)        3136      \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 11, 11, 64)        65600     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               819712    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 1,022,346\n",
            "Trainable params: 1,022,346\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGKQ-8bmtNn1"
      },
      "source": [
        "## Loss, optimization and compilation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-05-01T08:39:36.473837Z",
          "start_time": "2019-05-01T08:39:36.407595Z"
        },
        "collapsed": true,
        "id": "j1UmvSzLHm1R"
      },
      "source": [
        "# Loss \n",
        "\n",
        "loss = sparse_categorical_crossentropy # we use this cross entropy variant as the input is not \n",
        "                                       # one-hot encoded\n",
        "\n",
        "# Optimizer\n",
        "# Choose an optimizer - adaptive ones work well here\n",
        "optimizer = \"Adam\"\n",
        " \n",
        "# Compilation\n",
        "#############\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkPe16fDtNoJ"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-05-01T08:51:59.029061Z",
          "start_time": "2019-05-01T08:39:36.475186Z"
        },
        "collapsed": true,
        "id": "zZ1d14lFtNoM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6baa70cb-4a20-4849-e586-424fdc14e2fa"
      },
      "source": [
        "\n",
        "history = model.fit(x=train_images, y=train_labels,\n",
        "                    validation_data=(valid_images, valid_labels),\n",
        "                    epochs=epoch_count,\n",
        "                    batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "261/261 [==============================] - 4s 15ms/step - loss: 1.7566 - accuracy: 0.3472 - val_loss: 1.4009 - val_accuracy: 0.4900\n",
            "Epoch 2/30\n",
            "261/261 [==============================] - 4s 14ms/step - loss: 1.4137 - accuracy: 0.4872 - val_loss: 1.2577 - val_accuracy: 0.5582\n",
            "Epoch 3/30\n",
            "261/261 [==============================] - 4s 14ms/step - loss: 1.2819 - accuracy: 0.5421 - val_loss: 1.1254 - val_accuracy: 0.6066\n",
            "Epoch 4/30\n",
            "261/261 [==============================] - 4s 14ms/step - loss: 1.1977 - accuracy: 0.5760 - val_loss: 1.0437 - val_accuracy: 0.6394\n",
            "Epoch 5/30\n",
            "261/261 [==============================] - 4s 14ms/step - loss: 1.1239 - accuracy: 0.6045 - val_loss: 0.9807 - val_accuracy: 0.6574\n",
            "Epoch 6/30\n",
            "261/261 [==============================] - 4s 14ms/step - loss: 1.0674 - accuracy: 0.6259 - val_loss: 0.9824 - val_accuracy: 0.6660\n",
            "Epoch 7/30\n",
            "261/261 [==============================] - 4s 14ms/step - loss: 1.0187 - accuracy: 0.6445 - val_loss: 0.9366 - val_accuracy: 0.6706\n",
            "Epoch 8/30\n",
            "261/261 [==============================] - 4s 14ms/step - loss: 0.9709 - accuracy: 0.6622 - val_loss: 0.8547 - val_accuracy: 0.7114\n",
            "Epoch 9/30\n",
            "261/261 [==============================] - 4s 14ms/step - loss: 0.9422 - accuracy: 0.6705 - val_loss: 0.8538 - val_accuracy: 0.7098\n",
            "Epoch 10/30\n",
            "261/261 [==============================] - 4s 14ms/step - loss: 0.9051 - accuracy: 0.6823 - val_loss: 0.8761 - val_accuracy: 0.7026\n",
            "Epoch 11/30\n",
            "261/261 [==============================] - 4s 14ms/step - loss: 0.8875 - accuracy: 0.6918 - val_loss: 0.8107 - val_accuracy: 0.7170\n",
            "Epoch 12/30\n",
            "261/261 [==============================] - 4s 14ms/step - loss: 0.8559 - accuracy: 0.7010 - val_loss: 0.8051 - val_accuracy: 0.7244\n",
            "Epoch 13/30\n",
            "261/261 [==============================] - 4s 14ms/step - loss: 0.8383 - accuracy: 0.7054 - val_loss: 0.7834 - val_accuracy: 0.7308\n",
            "Epoch 14/30\n",
            "261/261 [==============================] - 4s 14ms/step - loss: 0.8221 - accuracy: 0.7116 - val_loss: 0.7698 - val_accuracy: 0.7388\n",
            "Epoch 15/30\n",
            "261/261 [==============================] - 4s 14ms/step - loss: 0.8003 - accuracy: 0.7196 - val_loss: 0.7446 - val_accuracy: 0.7488\n",
            "Epoch 16/30\n",
            "261/261 [==============================] - 4s 14ms/step - loss: 0.7810 - accuracy: 0.7260 - val_loss: 0.7409 - val_accuracy: 0.7454\n",
            "Epoch 17/30\n",
            "261/261 [==============================] - 4s 14ms/step - loss: 0.7567 - accuracy: 0.7343 - val_loss: 0.7449 - val_accuracy: 0.7482\n",
            "Epoch 18/30\n",
            "261/261 [==============================] - 4s 14ms/step - loss: 0.7455 - accuracy: 0.7367 - val_loss: 0.7411 - val_accuracy: 0.7484\n",
            "Epoch 19/30\n",
            "261/261 [==============================] - 4s 14ms/step - loss: 0.7396 - accuracy: 0.7383 - val_loss: 0.7266 - val_accuracy: 0.7572\n",
            "Epoch 20/30\n",
            "261/261 [==============================] - 4s 14ms/step - loss: 0.7168 - accuracy: 0.7475 - val_loss: 0.7219 - val_accuracy: 0.7554\n",
            "Epoch 21/30\n",
            "261/261 [==============================] - 4s 14ms/step - loss: 0.7100 - accuracy: 0.7495 - val_loss: 0.7195 - val_accuracy: 0.7574\n",
            "Epoch 22/30\n",
            "261/261 [==============================] - 4s 14ms/step - loss: 0.6977 - accuracy: 0.7546 - val_loss: 0.7259 - val_accuracy: 0.7592\n",
            "Epoch 23/30\n",
            "261/261 [==============================] - 4s 14ms/step - loss: 0.6798 - accuracy: 0.7627 - val_loss: 0.7160 - val_accuracy: 0.7636\n",
            "Epoch 24/30\n",
            "261/261 [==============================] - 4s 14ms/step - loss: 0.6751 - accuracy: 0.7622 - val_loss: 0.7105 - val_accuracy: 0.7634\n",
            "Epoch 25/30\n",
            "261/261 [==============================] - 4s 14ms/step - loss: 0.6657 - accuracy: 0.7659 - val_loss: 0.7212 - val_accuracy: 0.7520\n",
            "Epoch 26/30\n",
            "261/261 [==============================] - 4s 14ms/step - loss: 0.6544 - accuracy: 0.7697 - val_loss: 0.7358 - val_accuracy: 0.7554\n",
            "Epoch 27/30\n",
            "261/261 [==============================] - 4s 14ms/step - loss: 0.6490 - accuracy: 0.7705 - val_loss: 0.7169 - val_accuracy: 0.7580\n",
            "Epoch 28/30\n",
            "261/261 [==============================] - 4s 14ms/step - loss: 0.6456 - accuracy: 0.7723 - val_loss: 0.7117 - val_accuracy: 0.7646\n",
            "Epoch 29/30\n",
            " 69/261 [======>.......................] - ETA: 2s - loss: 0.6143 - accuracy: 0.7837"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-05-01T08:56:28.958057Z",
          "start_time": "2019-05-01T08:56:28.713031Z"
        },
        "collapsed": true,
        "id": "6GTGeChttNoi"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "def display_history(history):\n",
        "    \"\"\"Summarize history for accuracy and loss.\n",
        "    \"\"\"\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "    plt.title('Model accuracy')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'valid'], loc='upper left')\n",
        "    plt.show()\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('Model loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'valid'], loc='upper left')\n",
        "    plt.show()\n",
        "    \n",
        "display_history(history);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-05-01T08:52:07.228831Z",
          "start_time": "2019-05-01T08:52:07.222761Z"
        },
        "collapsed": true,
        "id": "tJzzUI-3xC_s"
      },
      "source": [
        "assert max(history.history['val_accuracy']) > 0.75"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7nD81aQtNo3"
      },
      "source": [
        "## Saving the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-05-01T08:52:10.803767Z",
          "start_time": "2019-05-01T08:52:10.663477Z"
        },
        "collapsed": true,
        "id": "XcFR3MkStNo5"
      },
      "source": [
        "model.save('my_model.h5')  # creates a HDF5 file 'my_model.h5'"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}